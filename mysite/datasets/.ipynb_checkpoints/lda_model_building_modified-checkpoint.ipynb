{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:42:32.204474Z",
     "iopub.status.busy": "2021-11-20T16:42:32.203794Z",
     "iopub.status.idle": "2021-11-20T16:42:32.460155Z",
     "shell.execute_reply": "2021-11-20T16:42:32.459440Z",
     "shell.execute_reply.started": "2021-11-20T16:42:32.204431Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, precision_score, precision_recall_curve, recall_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from os import path\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "from PIL import Image\n",
    "from wordcloud import ImageColorGenerator\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "import spacy\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import numpy as np\n",
    "#nltk.download('punkt')\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from textblob import TextBlob\n",
    "# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import datetime\n",
    "import warnings\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora, models\n",
    "#from pyLDAvis import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:42:58.967604Z",
     "iopub.status.busy": "2021-11-20T16:42:58.967345Z",
     "iopub.status.idle": "2021-11-20T16:42:59.114427Z",
     "shell.execute_reply": "2021-11-20T16:42:59.113687Z",
     "shell.execute_reply.started": "2021-11-20T16:42:58.967567Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"../input/twitter-airline-sentiment/Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:42:59.889727Z",
     "iopub.status.busy": "2021-11-20T16:42:59.889454Z",
     "iopub.status.idle": "2021-11-20T16:42:59.917530Z",
     "shell.execute_reply": "2021-11-20T16:42:59.916792Z",
     "shell.execute_reply.started": "2021-11-20T16:42:59.889699Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:43:12.322253Z",
     "iopub.status.busy": "2021-11-20T16:43:12.321549Z",
     "iopub.status.idle": "2021-11-20T16:43:12.335713Z",
     "shell.execute_reply": "2021-11-20T16:43:12.335032Z",
     "shell.execute_reply.started": "2021-11-20T16:43:12.322212Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets.airline_sentiment.value_counts()/len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive vs Negative Sentiment Categories Using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:43:14.987129Z",
     "iopub.status.busy": "2021-11-20T16:43:14.986479Z",
     "iopub.status.idle": "2021-11-20T16:43:15.006335Z",
     "shell.execute_reply": "2021-11-20T16:43:15.005645Z",
     "shell.execute_reply.started": "2021-11-20T16:43:14.987094Z"
    }
   },
   "outputs": [],
   "source": [
    "pos = tweets[tweets.airline_sentiment == 'positive']\n",
    "neg = tweets[tweets.airline_sentiment == 'negative']\n",
    "neu = tweets[tweets.airline_sentiment == 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:43:17.850056Z",
     "iopub.status.busy": "2021-11-20T16:43:17.849297Z",
     "iopub.status.idle": "2021-11-20T16:43:17.855738Z",
     "shell.execute_reply": "2021-11-20T16:43:17.854929Z",
     "shell.execute_reply.started": "2021-11-20T16:43:17.849998Z"
    }
   },
   "outputs": [],
   "source": [
    "neg = neg.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### negative tweets categories - overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:43:19.890030Z",
     "iopub.status.busy": "2021-11-20T16:43:19.889464Z",
     "iopub.status.idle": "2021-11-20T16:43:19.998252Z",
     "shell.execute_reply": "2021-11-20T16:43:19.997472Z",
     "shell.execute_reply.started": "2021-11-20T16:43:19.889992Z"
    }
   },
   "outputs": [],
   "source": [
    "text = neg.text.dropna()\n",
    "text = text.to_string().lower()\n",
    "print(\"There are {} wor ds in the combination of all review.\".format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:43:22.356493Z",
     "iopub.status.busy": "2021-11-20T16:43:22.355560Z",
     "iopub.status.idle": "2021-11-20T16:43:22.431763Z",
     "shell.execute_reply": "2021-11-20T16:43:22.430761Z",
     "shell.execute_reply.started": "2021-11-20T16:43:22.356449Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "char_mask = np.array(Image.open(\"tweey.png\"))\n",
    "\n",
    "\n",
    "def transform_format(val):\n",
    "    if val == 0:\n",
    "        return 255\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "def grey_color_func(word, font_size, position,orientation,random_state=None, **kwargs):\n",
    "    return(\"hsl(26,100%%, %d%%)\" % np.random.randint(50,80))\n",
    "\n",
    "    \n",
    "transformed_mask = np.ndarray((char_mask.shape[0],char_mask.shape[1]), np.int32)\n",
    "for i in range(len(char_mask)):\n",
    "    transformed_mask[i] = list(map(transform_format, char_mask[i]))\n",
    "    \n",
    "    \n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"american\", \"air\",\"airline\",\"thank\",\"united\",\"us\",\"airways\",\"virgin\",\"america\",\"jetblue\",\n",
    "                 \"usairway\",\"usairways\",\"flight\",\"americanair\",\"southwestair\",\"southwestairlines\",\n",
    "                 \"southwestairway\",\"southwestairways\",\"virginamerica\",\"really\",\"will\",\"going\",\"thanks\",\"thankyou\",\n",
    "                 \"please\",\"got\",\"let\",\"take\",\"help\",\"already\",\"never\",\"now\",\"told\",\"guy\",\"new\",\"sure\",\"still\",\"amp\",\n",
    "                 \"plane\",\"tell\",\"ye\",\"trying\",\"yes\"])\n",
    "\n",
    "textwc = WordCloud(stopwords=stopwords,mask=transformed_mask, max_words=200,random_state=1,background_color=\"#c2e0fc\").generate(text)\n",
    "plt.figure(figsize=[20,10])\n",
    "plt.imshow(textwc.recolor(color_func=grey_color_func, random_state=3),\n",
    "           interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('/Users/jenniferwu/Desktop/MSBA/Spring 2020/NLP/final project/wcneg.png',transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Model to Find Topics for Negative Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:46:23.915515Z",
     "iopub.status.busy": "2021-11-20T16:46:23.914770Z",
     "iopub.status.idle": "2021-11-20T16:46:24.631040Z",
     "shell.execute_reply": "2021-11-20T16:46:24.630252Z",
     "shell.execute_reply.started": "2021-11-20T16:46:23.915477Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:46:27.427925Z",
     "iopub.status.busy": "2021-11-20T16:46:27.427182Z",
     "iopub.status.idle": "2021-11-20T16:47:33.584491Z",
     "shell.execute_reply": "2021-11-20T16:47:33.583764Z",
     "shell.execute_reply.started": "2021-11-20T16:46:27.427880Z"
    }
   },
   "outputs": [],
   "source": [
    "#getting the adjectives and conjuction using spacy\n",
    "doc = []\n",
    "t = []\n",
    "for row in range(len(neg.text)):\n",
    "    doc.append(nlp(neg.text[row]))\n",
    "    t.append([str(token) for token in doc[row] if (token.pos_ in [\"ADJ\",\"CCONJ\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:47:57.846921Z",
     "iopub.status.busy": "2021-11-20T16:47:57.846621Z",
     "iopub.status.idle": "2021-11-20T16:47:57.854886Z",
     "shell.execute_reply": "2021-11-20T16:47:57.853990Z",
     "shell.execute_reply.started": "2021-11-20T16:47:57.846888Z"
    }
   },
   "outputs": [],
   "source": [
    "ts = set()\n",
    "for i in range(len(t)):\n",
    "    ts.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:48:02.913603Z",
     "iopub.status.busy": "2021-11-20T16:48:02.913143Z",
     "iopub.status.idle": "2021-11-20T16:48:02.939374Z",
     "shell.execute_reply": "2021-11-20T16:48:02.938532Z",
     "shell.execute_reply.started": "2021-11-20T16:48:02.913569Z"
    }
   },
   "outputs": [],
   "source": [
    "#cities = pd.read_csv(\"https://raw.githubusercontent.com/grammakov/USA-cities-and-states/master/us_cities_states_counties.csv\",sep=\"|\")\n",
    "#cities = cities.iloc[:,:2]\n",
    "#cities.drop_duplicates(keep='first',inplace=True)\n",
    "\n",
    "#preprocess data\n",
    "def preprocess(text):\n",
    "    stopwords = set(STOPWORDS)\n",
    "    stopwords.update([\"american\", \"air\",\"airline\",\"thank\",\"united\",\"us\",\"airways\",\"virgin\",\"america\",\"jetblue\",\"youre\",\"extremely\",\n",
    "                     \"usairway\",\"usairways\",\"flight\",\"americanair\",\"southwestair\",\"southwestairlines\",\"arbitrarily\",\"dream\",\"crazy\",\n",
    "                     \"southwestairway\",\"southwestairways\",\"virginamerica\",\"really\",\"will\",\"going\",\"thanks\",\"thankyou\",\"passengersdont\",\n",
    "                     \"please\",\"got\",\"let\",\"take\",\"help\",\"already\",\"never\",\"now\",\"told\",\"guy\",\"new\",\"sure\",\"still\",\"amp\",\"continue\",\n",
    "                     \"plane\",\"tell\",\"ye\",\"trying\",\"yes\",\"guy\",\"much\",\"appreciate\", \"thx\",\"back\",\"ok\",\"good\",\"credit\",\"aacom\",\n",
    "                     \"flying\",\"love\",\"great\",\"awesome\",\"see\",\"nice\",\"alway\",\"httptcojwl26g6lrw\",\"dontflythem\",\"motherinlaw\",\"night\",\n",
    "                     \"nogearnotraining\",\"seriously\",\"didnt\",\"coudnt\",\"cant\",\"wont\",\"dont\",\"wat\",\"buffaloniagara\",\"hasshe\",\"morning\",\n",
    "                     \"woulda\",\"people\",\"try\",\"youve\",\"youd\",\"yours\",\"flightled\",\"tomorrow\",\"today\",\"wat\",\"jfkyou\",\"flite\",\"cause\",\n",
    "                     \"flightr\",\"flight\",\"need\",\"hours\",\"nooooo\",\"like\",\"doesnt\",\"right\",\"talk\",\"tweet\",\"mention\",\"pbijfk\",\"ridiculuous\",\n",
    "                     \"wasnt\",\"suppose\",\"want\",\"understand\",\"come\",\"work\",\"worse\",\"treat\",\"think\",\"know\",\"worst\",\"paulo\",\"staduim\",\n",
    "                     \"wouldnt\",\"stay\",\"away\",\"wont\",\"werent\",\"happen\",\"sorry\",\"havent\",\"tonight\",\"drive\",\"life\",\"thing\",\"aa951\",\n",
    "                     \"whats\",\"theyre\",\"better\",\"thats\",\"allow\",\"hope\",\"stop\",\"cool\",\"niece\",\"happy\",\"word\",\"customercant\",\n",
    "                     \"suck\",\"sunday\",\"monday\",\"tuesday\",\"wednesday\",\"thursday\",\"friday\",\"saturday\",\"weekend\",\"ruin\",\"shouldnt\",\n",
    "                     \"miami\",\"los angeles\",\"new york\",\"chicago\",\"dallas\",\"apparently\",\"itover\",\"someones\",\"savannah\",\"lucymay\",\n",
    "                     \"betterother\",\"instead\",\"look\",\"hopefully\",\"yesterday\",\"antonio\",\"unacceptable\",\"folks\",\"record\",'arent',\n",
    "                     \"miss\",\"hang\",\"wrong\",\"stick\",\"grind\",\"tarmac\",\"theres\",\"forget\",\"terrible\",\"clothe\",\"terrible\",\"break\",\n",
    "                     \"actually\",\"frustrate\",\"correct\",\"ridiculous\",\"expect\",\"different\",\"pathetic\",\"bother\",\"follow\",\"fault\",\n",
    "                     \"impossible\",\"point\",\"cover\",\"person\",\"ask\",\"speak\",\"things\",\"earlier\",\"mean\",\"select\",\"minutes\",\n",
    "                     \"unite\",\"horrible\",\"country\",\"leave\",\"speak\",\"apologize\",\"faster\",\"hop\",\"confuse\",\"lose\",\"flightd\",\"hear\",\n",
    "                     \"literally\",\"years\",\"surprise\",\"bump\",\"fail\",\"compensate\",\"hand\",\"helpful\",\"upset\",\"friend\",\"excuse\",\"claim\",\n",
    "                     \"situation\",\"multiple\",\"weather\",\"choose\",\"company\",\"believe\",\"question\",\"kick\",\"anymore\",\"awful\",\"delta\",\n",
    "                      \"dozen\",\"medical\",\"completely\",\"finally\", \"waste\",\"shock\",\"annoy\",\"maybe\",\"strand\",\"mess\",\"finally\",\n",
    "                      \"plan\",\"place\",\"apology\",\"center\",\"plan\",\"twitter\",\"promise\",\"prefer\",\"count\",\"maybe\",\"shock\",\"longer\",\"meet\",\n",
    "                         \"important\",\"drop\"])\n",
    " \n",
    "    #stopwords.update([i for i in ts])\n",
    "    # stopwords.update([str(i).lower() for i in cities.City]) #removing City names in US\n",
    "    r = re.compile(r'(?<=\\@)(\\w+)') #remove words after tags --> usually twitter account\n",
    "    ra = re.compile(r'(?<=\\#)(\\w+)') #remove words after hashtags\n",
    "    ro = re.compile(r'(flt\\d*)') #remove words after flight number\n",
    "    names = r.findall(text.lower())\n",
    "    hashtag = ra.findall(text.lower())\n",
    "    flight = ro.findall(text.lower())\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    def stem_tokens(tokens, lemmatize):\n",
    "        lemmatized = []\n",
    "        for item in tokens:\n",
    "            lemmatized.append(lmtzr.lemmatize(item,'v'))\n",
    "        return lemmatized\n",
    "    def deEmojify(inputString):\n",
    "        return inputString.encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    #doc = nlp(text)\n",
    "    text = deEmojify(text)\n",
    "    soup = BeautifulSoup(text)\n",
    "    text = soup.get_text()\n",
    "    text = \"\".join([ch.lower() for ch in text if ch not in string.punctuation])\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [ch for ch in tokens if len(ch)>4] #remove words with character length below 2\n",
    "    tokens = [ch for ch in tokens if len(ch)<=15] #remove words with character length above 15 \n",
    "    lemm = stem_tokens(tokens, lmtzr)\n",
    "    lemstop = [i for i in lemm if i not in stopwords]\n",
    "    lemstopcl = [i for i in lemstop if i not in names]\n",
    "    lemstopcl = [i for i in lemstopcl if i not in hashtag]\n",
    "    lemstopcl = [i for i in lemstopcl if i not in flight]\n",
    "    lemstopcl = [i for i in lemstopcl if not i.isdigit()]\n",
    "    #lemstopcl1 = [i for i in lemstopcl if i not in t]\n",
    "    return lemstopcl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:48:20.859410Z",
     "iopub.status.busy": "2021-11-20T16:48:20.858922Z",
     "iopub.status.idle": "2021-11-20T16:48:20.867085Z",
     "shell.execute_reply": "2021-11-20T16:48:20.866269Z",
     "shell.execute_reply.started": "2021-11-20T16:48:20.859372Z"
    }
   },
   "outputs": [],
   "source": [
    "#testing the tokenizer\n",
    "text = \"\"\"@Jenny @Joe and @Susan we are all very dissapointing in your service with the LONG delays\n",
    "            for flt15539 560948 #notdoingthisanymore #dontflythem in New York to Chicago\"\"\"\n",
    "preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:48:22.815407Z",
     "iopub.status.busy": "2021-11-20T16:48:22.814828Z",
     "iopub.status.idle": "2021-11-20T16:48:28.757054Z",
     "shell.execute_reply": "2021-11-20T16:48:28.756276Z",
     "shell.execute_reply.started": "2021-11-20T16:48:22.815369Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "neg['token']=neg.text.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:48:28.759212Z",
     "iopub.status.busy": "2021-11-20T16:48:28.758467Z",
     "iopub.status.idle": "2021-11-20T16:48:28.919190Z",
     "shell.execute_reply": "2021-11-20T16:48:28.918405Z",
     "shell.execute_reply.started": "2021-11-20T16:48:28.759171Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_docs=neg['token']\n",
    "id2word = gensim.corpora.Dictionary(processed_docs)\n",
    "corpus = [id2word.doc2bow(text) for text in processed_docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:48:36.580875Z",
     "iopub.status.busy": "2021-11-20T16:48:36.580390Z",
     "iopub.status.idle": "2021-11-20T16:48:36.604014Z",
     "shell.execute_reply": "2021-11-20T16:48:36.603322Z",
     "shell.execute_reply.started": "2021-11-20T16:48:36.580824Z"
    }
   },
   "outputs": [],
   "source": [
    "id2word.save_as_text('dict.txt')\n",
    "id2word.save('id2word.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:49:12.776669Z",
     "iopub.status.busy": "2021-11-20T16:49:12.776411Z",
     "iopub.status.idle": "2021-11-20T16:49:12.784091Z",
     "shell.execute_reply": "2021-11-20T16:49:12.783000Z",
     "shell.execute_reply.started": "2021-11-20T16:49:12.776639Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, start, stop):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, stop):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus, \n",
    "                                                num_topics=num_topics,\n",
    "                                                id2word=id2word,\n",
    "                                               random_state=123,\n",
    "                                               alpha='auto',\n",
    "                                                eta='auto',\n",
    "                                               per_word_topics=True)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:49:14.761783Z",
     "iopub.status.busy": "2021-11-20T16:49:14.761525Z",
     "iopub.status.idle": "2021-11-20T16:49:35.795644Z",
     "shell.execute_reply": "2021-11-20T16:49:35.794900Z",
     "shell.execute_reply.started": "2021-11-20T16:49:14.761754Z"
    }
   },
   "outputs": [],
   "source": [
    "start=3\n",
    "stop=9\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, \n",
    "                                                        corpus=corpus, \n",
    "                                                        texts=processed_docs,\n",
    "                                                        start=start, \n",
    "                                                        stop=stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:49:35.798635Z",
     "iopub.status.busy": "2021-11-20T16:49:35.798207Z",
     "iopub.status.idle": "2021-11-20T16:49:36.025735Z",
     "shell.execute_reply": "2021-11-20T16:49:36.025007Z",
     "shell.execute_reply.started": "2021-11-20T16:49:35.798598Z"
    }
   },
   "outputs": [],
   "source": [
    "x = range(start, stop)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(x, coherence_values, color = \"blue\",marker=\".\")\n",
    "plt.xlabel(\"Num Topics\", size=14)\n",
    "plt.ylabel(\"Coherence score\", size=14)\n",
    "plt.title('Choosing The Number of Topics Based on The Coherence Score',size=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing 8 as the number of topics for negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:52:55.076549Z",
     "iopub.status.busy": "2021-11-20T16:52:55.076288Z",
     "iopub.status.idle": "2021-11-20T16:55:31.517233Z",
     "shell.execute_reply": "2021-11-20T16:55:31.516428Z",
     "shell.execute_reply.started": "2021-11-20T16:52:55.076520Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create Dictionary\n",
    "id2word = gensim.corpora.Dictionary(processed_docs)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in processed_docs]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model4 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=8, \n",
    "                                           random_state=123,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=10,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           eta='auto',\n",
    "                                           iterations=125,\n",
    "                                           per_word_topics=True)\n",
    "doc_lda = lda_model4[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:52:17.053015Z",
     "iopub.status.busy": "2021-11-20T16:52:17.051682Z",
     "iopub.status.idle": "2021-11-20T16:52:17.068457Z",
     "shell.execute_reply": "2021-11-20T16:52:17.067139Z",
     "shell.execute_reply.started": "2021-11-20T16:52:17.052972Z"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(lda_model4.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:55:31.519418Z",
     "iopub.status.busy": "2021-11-20T16:55:31.518688Z",
     "iopub.status.idle": "2021-11-20T16:55:34.158800Z",
     "shell.execute_reply": "2021-11-20T16:55:34.158050Z",
     "shell.execute_reply.started": "2021-11-20T16:55:31.519380Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model4.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model4, texts=processed_docs, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:56:07.373190Z",
     "iopub.status.busy": "2021-11-20T16:56:07.372702Z",
     "iopub.status.idle": "2021-11-20T16:56:07.392529Z",
     "shell.execute_reply": "2021-11-20T16:56:07.391785Z",
     "shell.execute_reply.started": "2021-11-20T16:56:07.373152Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_model4.save('lda_model4.model')\n",
    "lda_model4=models.LdaModel.load('lda_model4.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:56:10.315479Z",
     "iopub.status.busy": "2021-11-20T16:56:10.314951Z",
     "iopub.status.idle": "2021-11-20T16:56:10.339484Z",
     "shell.execute_reply": "2021-11-20T16:56:10.338526Z",
     "shell.execute_reply.started": "2021-11-20T16:56:10.315443Z"
    }
   },
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary.load('id2word.dict')\n",
    "\n",
    "unseen_document = '''United has the WORST customer experience ever! first the website was down, then the boarding and checkin processes w so complicated and slow\n",
    "                    '''\n",
    "bow_vector = id2word.doc2bow(preprocess(unseen_document))\n",
    "result = lda_model4.get_document_topics(bow_vector)\n",
    "resultdict = dict(result)\n",
    "\n",
    "\n",
    "orddict = sorted(resultdict, key=resultdict.get, reverse=True)\n",
    "Keymax = 1\n",
    "if resultdict[orddict[0]]-resultdict[orddict[1]] <=.08:\n",
    "    Keymax +=orddict[1]\n",
    "    print(\"Predicted topic: \",orddict[1]+1)\n",
    "    print(\"Probability Score: \",resultdict[orddict[1]])\n",
    "else:\n",
    "    Keymax +=orddict[0]\n",
    "    print(\"Predicted topic: \",orddict[0]+1)\n",
    "    print(\"Probability Score: \",resultdict[orddict[0]])\n",
    "\n",
    "#Keymax = max(resultdict, key=resultdict.get)+1\n",
    "#print(\"Predicted Topic :\", Keymax) \n",
    "\n",
    "\n",
    "if Keymax == 1:\n",
    "    print('Delay and Customer Service')\n",
    "elif Keymax == 2:\n",
    "    print('Baggage Issue')\n",
    "elif Keymax == 3:\n",
    "    print('Reschedule and Refund')\n",
    "elif Keymax == 4:\n",
    "    print('Phone and Online Booking')\n",
    "elif Keymax == 5:\n",
    "    print('Reservation Issue')\n",
    "elif Keymax == 6:\n",
    "    print('Seating Preferences')\n",
    "elif Keymax == 7:\n",
    "    print('Extra Charges')\n",
    "else:\n",
    "    print('Customer Experience')\n",
    "print(\"\\n\")\n",
    "\n",
    "for index, score in resultdict.items():\n",
    "    print(\"Score: {}\\n Topic: {}\\n Keywords:{} \\n\".format(score, index+1, lda_model4.print_topic(index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:56:28.051570Z",
     "iopub.status.busy": "2021-11-20T16:56:28.050836Z",
     "iopub.status.idle": "2021-11-20T16:56:29.331523Z",
     "shell.execute_reply": "2021-11-20T16:56:29.330808Z",
     "shell.execute_reply.started": "2021-11-20T16:56:28.051533Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "from pyLDAvis import gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model4, corpus, id2word,sort_topics=False)\n",
    "pyLDAvis.save_html(vis, 'ldaviz.html')\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Sentiment Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:56:45.999590Z",
     "iopub.status.busy": "2021-11-20T16:56:45.999101Z",
     "iopub.status.idle": "2021-11-20T16:56:47.311325Z",
     "shell.execute_reply": "2021-11-20T16:56:47.310609Z",
     "shell.execute_reply.started": "2021-11-20T16:56:45.999547Z"
    }
   },
   "outputs": [],
   "source": [
    "lcorp =[]\n",
    "for i in range(len(corpus)):\n",
    "    lcorp.append(lda_model4.get_document_topics(corpus[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:56:47.313467Z",
     "iopub.status.busy": "2021-11-20T16:56:47.312872Z",
     "iopub.status.idle": "2021-11-20T16:56:47.338172Z",
     "shell.execute_reply": "2021-11-20T16:56:47.337501Z",
     "shell.execute_reply.started": "2021-11-20T16:56:47.313421Z"
    }
   },
   "outputs": [],
   "source": [
    "topicscore = []\n",
    "for i in range(len(lcorp)):\n",
    "    topicscore.append(max(lcorp[i], key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:56:49.698883Z",
     "iopub.status.busy": "2021-11-20T16:56:49.698591Z",
     "iopub.status.idle": "2021-11-20T16:56:49.720917Z",
     "shell.execute_reply": "2021-11-20T16:56:49.720215Z",
     "shell.execute_reply.started": "2021-11-20T16:56:49.698837Z"
    }
   },
   "outputs": [],
   "source": [
    "neg['topic_no']=[i[0]+1 for i in topicscore]\n",
    "neg['topic_prob']=[i[1] for i in topicscore]\n",
    "keywords=[]\n",
    "for row in range(0,7):\n",
    "    keywords.append([i[0] for i in lda_model4.show_topic(row)])\n",
    "    \n",
    "kywrd = []\n",
    "kywrd.append([\" , \".join(keywords[0])])\n",
    "kywrd.append([\" , \".join(keywords[1])])\n",
    "kywrd.append([\" , \".join(keywords[2])])\n",
    "kywrd.append([\" , \".join(keywords[3])])\n",
    "kywrd.append([\" , \".join(keywords[4])])\n",
    "kywrd.append([\" , \".join(keywords[5])])\n",
    "kywrd.append([\" , \".join(keywords[6])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Topic Categorization\n",
    "- Topic 1 --> Delay and Customer Service\n",
    "- Topic 2 --> Baggage Issue\n",
    "- Topic 3 --> Reschedule and Refund\n",
    "- Topic 4 --> Phone and Online Booking\n",
    "- Topic 5 --> Reservation Issue\n",
    "- Topic 6 --> Seating Preferences\n",
    "- Topic 7 --> Extra Charges\n",
    "- Topic 8 --> Customer Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T16:56:53.064779Z",
     "iopub.status.busy": "2021-11-20T16:56:53.064338Z",
     "iopub.status.idle": "2021-11-20T16:56:53.082953Z",
     "shell.execute_reply": "2021-11-20T16:56:53.081076Z",
     "shell.execute_reply.started": "2021-11-20T16:56:53.064743Z"
    }
   },
   "outputs": [],
   "source": [
    "negf=neg\n",
    "negf['keywords']=[kywrd[i-1] for i in negf.topic_no]\n",
    "\n",
    "topic_desc = []\n",
    "for i in negf.topic_no:\n",
    "    if i == 1:\n",
    "        topic_desc.append('Delay and Customer Service')\n",
    "    elif i == 2:\n",
    "        topic_desc.append('Baggage Issue')\n",
    "    elif i == 3:\n",
    "        topic_desc.append('Reschedule and Refund')\n",
    "    elif i == 4:\n",
    "        topic_desc.append('Phone and Online Booking')\n",
    "    elif i == 5:\n",
    "        topic_desc.append('Reservation Issue')\n",
    "    elif i == 6:\n",
    "        topic_desc.append('Seating Preferences')\n",
    "    elif i == 7:\n",
    "        topic_desc.append('Extra Charges')\n",
    "    else:\n",
    "        topic_desc.append('Customer Experience')\n",
    "        \n",
    "negf['topic_desc']=topic_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
